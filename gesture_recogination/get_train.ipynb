{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  20480512  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 20,605,322\n",
      "Trainable params: 20,605,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train for 709 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "709/709 [==============================] - 277s 391ms/step - loss: 2.2636 - accuracy: 0.1507\n",
      "Epoch 2/100\n",
      "709/709 [==============================] - 260s 367ms/step - loss: 2.2321 - accuracy: 0.1790 - val_loss: 2.2659 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "709/709 [==============================] - 262s 369ms/step - loss: 2.1519 - accuracy: 0.2308\n",
      "Epoch 4/100\n",
      "709/709 [==============================] - 261s 368ms/step - loss: 1.9062 - accuracy: 0.3461 - val_loss: 1.6127 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "709/709 [==============================] - 259s 365ms/step - loss: 1.4899 - accuracy: 0.5057\n",
      "Epoch 6/100\n",
      "709/709 [==============================] - 264s 372ms/step - loss: 1.0686 - accuracy: 0.6539 - val_loss: 0.8442 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "709/709 [==============================] - 262s 369ms/step - loss: 0.7396 - accuracy: 0.7702\n",
      "Epoch 8/100\n",
      "709/709 [==============================] - 285s 402ms/step - loss: 0.5082 - accuracy: 0.8455 - val_loss: 0.5880 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "709/709 [==============================] - 278s 392ms/step - loss: 0.3694 - accuracy: 0.8903\n",
      "Epoch 10/100\n",
      "709/709 [==============================] - 269s 379ms/step - loss: 0.2802 - accuracy: 0.9157 - val_loss: 0.3973 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "709/709 [==============================] - 267s 377ms/step - loss: 0.2308 - accuracy: 0.9318\n",
      "Epoch 12/100\n",
      "709/709 [==============================] - 255s 360ms/step - loss: 0.1862 - accuracy: 0.9441 - val_loss: 0.3193 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "709/709 [==============================] - 253s 357ms/step - loss: 0.1560 - accuracy: 0.9526\n",
      "Epoch 14/100\n",
      "709/709 [==============================] - 255s 359ms/step - loss: 0.1280 - accuracy: 0.9619 - val_loss: 0.4567 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "709/709 [==============================] - 255s 359ms/step - loss: 0.1109 - accuracy: 0.9671\n",
      "Epoch 16/100\n",
      "709/709 [==============================] - 254s 359ms/step - loss: 0.1020 - accuracy: 0.9687 - val_loss: 0.1029 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "709/709 [==============================] - 254s 358ms/step - loss: 0.0871 - accuracy: 0.9717\n",
      "Epoch 18/100\n",
      "709/709 [==============================] - 258s 363ms/step - loss: 0.0804 - accuracy: 0.9753 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "709/709 [==============================] - 244s 345ms/step - loss: 0.0702 - accuracy: 0.9785\n",
      "Epoch 20/100\n",
      "709/709 [==============================] - 244s 344ms/step - loss: 0.0612 - accuracy: 0.9812 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "709/709 [==============================] - 246s 346ms/step - loss: 0.0549 - accuracy: 0.9843\n",
      "Epoch 22/100\n",
      "709/709 [==============================] - 245s 346ms/step - loss: 0.0490 - accuracy: 0.9867 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "709/709 [==============================] - 246s 347ms/step - loss: 0.0397 - accuracy: 0.9892\n",
      "Epoch 24/100\n",
      "709/709 [==============================] - 246s 346ms/step - loss: 0.0426 - accuracy: 0.9877 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "709/709 [==============================] - 248s 349ms/step - loss: 0.0347 - accuracy: 0.9895\n",
      "Epoch 26/100\n",
      "709/709 [==============================] - 246s 347ms/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "709/709 [==============================] - 245s 346ms/step - loss: 0.0322 - accuracy: 0.9898\n",
      "Epoch 28/100\n",
      "709/709 [==============================] - 247s 348ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.1230 - val_accuracy: 0.9000\n",
      "Epoch 29/100\n",
      "709/709 [==============================] - 251s 355ms/step - loss: 0.0297 - accuracy: 0.9904\n",
      "Epoch 30/100\n",
      "709/709 [==============================] - 287s 405ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "709/709 [==============================] - 284s 401ms/step - loss: 0.0225 - accuracy: 0.9939\n",
      "Epoch 32/100\n",
      "709/709 [==============================] - 325s 458ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "709/709 [==============================] - 368s 520ms/step - loss: 0.0214 - accuracy: 0.9940\n",
      "Epoch 34/100\n",
      "709/709 [==============================] - 332s 469ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 7.0159e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "709/709 [==============================] - 338s 477ms/step - loss: 0.0158 - accuracy: 0.9954\n",
      "Epoch 36/100\n",
      "709/709 [==============================] - 338s 476ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "709/709 [==============================] - 333s 469ms/step - loss: 0.0135 - accuracy: 0.9964\n",
      "Epoch 38/100\n",
      "709/709 [==============================] - 349s 492ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "709/709 [==============================] - 343s 484ms/step - loss: 0.0135 - accuracy: 0.9962\n",
      "Epoch 40/100\n",
      "709/709 [==============================] - 341s 481ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 7.1485e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "709/709 [==============================] - 341s 482ms/step - loss: 0.0088 - accuracy: 0.9982\n",
      "Epoch 42/100\n",
      "709/709 [==============================] - 345s 486ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "709/709 [==============================] - 347s 489ms/step - loss: 0.0108 - accuracy: 0.9977\n",
      "Epoch 44/100\n",
      "709/709 [==============================] - 338s 476ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 8.9927e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "709/709 [==============================] - 330s 466ms/step - loss: 0.0121 - accuracy: 0.9972\n",
      "Epoch 46/100\n",
      "709/709 [==============================] - 333s 469ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 7.5853e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "709/709 [==============================] - 334s 472ms/step - loss: 0.0068 - accuracy: 0.9988\n",
      "Epoch 48/100\n",
      "476/709 [===================>..........] - ETA: 1:47 - loss: 0.0098 - accuracy: 0.9978"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "import os \n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "    path_root = pathlib.Path(path)\n",
    "    # print(path_root)\n",
    "    # for item in path_root.iterdir():\n",
    "    #     print(item)\n",
    "    image_paths = list(path_root.glob('*/*'))\n",
    "    image_paths = [str(path) for path in image_paths]\n",
    "    random.shuffle(image_paths)\n",
    "    image_count = len(image_paths)\n",
    "    # print(image_count)\n",
    "    # print(image_paths[:10])\n",
    "\n",
    "    label_names = sorted(item.name for item in path_root.glob('*/') if item.is_dir())\n",
    "    # print(label_names)\n",
    "    label_name_index = dict((name, index) for index, name in enumerate(label_names))\n",
    "    # print(label_name_index)\n",
    "    image_labels = [label_name_index[pathlib.Path(path).parent.name] for path in image_paths]\n",
    "    # print(\"First 10 labels indices: \", image_labels[:10])\n",
    "    return image_paths,image_labels,image_count\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [100, 100])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    # image = tf.reshape(image,[100*100*3])\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path,label):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image),label\n",
    "\n",
    "def creat_dataset(image_paths,image_labels,bitch_size):\n",
    "    db = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
    "    dataset = db.map(load_and_preprocess_image).batch(bitch_size)    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def train_model(train_data,test_data):\n",
    "    #构建模型\n",
    "    network = keras.Sequential([\n",
    "            keras.layers.Conv2D(32,kernel_size=[5,5],padding=\"same\",activation=tf.nn.relu),\n",
    "            keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "            keras.layers.Conv2D(64,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "            keras.layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "            keras.layers.Conv2D(64,kernel_size=[3,3],padding=\"same\",activation=tf.nn.relu),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(512,activation='relu'),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(128,activation='relu'),\n",
    "            keras.layers.Dense(10)])\n",
    "    network.build(input_shape=(None,100,100,3))\n",
    "    network.summary()\n",
    "\n",
    "    network.compile(optimizer=optimizers.SGD(lr=0.001),\n",
    "            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "    )\n",
    "    #模型训练\n",
    "    network.fit(train_data, epochs = 100,validation_data=test_data,validation_freq=2)  \n",
    "    network.evaluate(test_data)\n",
    "\n",
    "    tf.saved_model.save(network,'D:\\\\Code-class\\\\gesture_recogination\\\\model\\\\')\n",
    "    print(\"保存模型成功\")\n",
    "\n",
    "\n",
    "\n",
    "    # Convert Keras model to ConcreteFunction\n",
    "    full_model = tf.function(lambda x: network(x))\n",
    "    full_model = full_model.get_concrete_function(\n",
    "    tf.TensorSpec(network.inputs[0].shape, network.inputs[0].dtype))\n",
    "\n",
    "    # Get frozen ConcreteFunction\n",
    "    frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "    frozen_func.graph.as_graph_def()\n",
    "\n",
    "    layers = [op.name for op in frozen_func.graph.get_operations()]\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model layers: \")\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Frozen model inputs: \")\n",
    "    print(frozen_func.inputs)\n",
    "    print(\"Frozen model outputs: \")\n",
    "    print(frozen_func.outputs)\n",
    "\n",
    "    # Save frozen graph from frozen ConcreteFunction to hard drive\n",
    "    tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
    "            logdir=\"D:\\\\Code-class\\\\gesture_recogination\\\\model\\\\frozen_model\\\\\",\n",
    "            name=\"frozen_graph.pb\",\n",
    "            as_text=False)\n",
    "    print(\"模型转换完成，训练结束\")\n",
    "\n",
    "\n",
    "if  __name__ == \"__main__\":\n",
    "    print(tf.__version__)\n",
    "    train_path = 'D:\\\\Code-class\\\\gesture_recogination\\\\Dataset'\n",
    "#     train_path = 'D:\\\\code\\\\PYTHON\\\\gesture_recognition\\\\Dataset'\n",
    "    test_path = 'D:\\\\Code-class\\\\gesture_recogination\\\\testdata' \n",
    "    image_paths,image_labels,_ = read_data(train_path)\n",
    "    train_data = creat_dataset(image_paths,image_labels,16)\n",
    "    image_paths,image_labels,_ = read_data(test_path)\n",
    "    test_data = creat_dataset(image_paths,image_labels,16)\n",
    "    train_model(train_data,test_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
