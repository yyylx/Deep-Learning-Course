{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入您要进行迭代的次数：5\n",
      "请输入你要调整的学习率：0.01\n",
      "             CRIM         ZN       INDUS         CHAS         NOX          RM  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO       LSTAT  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
      "\n",
      "             MEDV  \n",
      "count  506.000000  \n",
      "mean    22.532806  \n",
      "std      9.197104  \n",
      "min      5.000000  \n",
      "25%     17.025000  \n",
      "50%     21.200000  \n",
      "75%     25.000000  \n",
      "max     50.000000  \n",
      "epoch=1    loss=60.6700667     b=10.9570494     \n",
      "w=\n",
      "[[-0.8406434 ]\n",
      " [ 2.9479244 ]\n",
      " [ 0.01897817]\n",
      " [ 0.76616687]\n",
      " [ 1.4729964 ]\n",
      " [ 9.710587  ]\n",
      " [ 2.8675199 ]\n",
      " [ 3.0750992 ]\n",
      " [ 0.6067519 ]\n",
      " [ 0.18551858]\n",
      " [ 1.2702627 ]\n",
      " [-3.8737671 ]]\n",
      "epoch=2    loss=47.3567756     b=16.0813446     \n",
      "w=\n",
      "[[-2.037796  ]\n",
      " [ 5.053964  ]\n",
      " [-1.6786699 ]\n",
      " [ 2.9338531 ]\n",
      " [ 0.11578549]\n",
      " [16.608107  ]\n",
      " [ 2.652759  ]\n",
      " [ 3.9326677 ]\n",
      " [-1.5011959 ]\n",
      " [-2.7158537 ]\n",
      " [-1.3429325 ]\n",
      " [-8.980129  ]]\n",
      "epoch=3    loss=34.7607498     b=17.4146843     \n",
      "w=\n",
      "[[ -2.550626  ]\n",
      " [  4.778253  ]\n",
      " [ -1.7837183 ]\n",
      " [  3.6782413 ]\n",
      " [ -0.26793104]\n",
      " [ 19.4034    ]\n",
      " [  2.5145814 ]\n",
      " [  2.3347027 ]\n",
      " [ -0.654225  ]\n",
      " [ -3.0487502 ]\n",
      " [ -3.287651  ]\n",
      " [-11.981437  ]]\n",
      "epoch=4    loss=31.1882071     b=17.8238049     \n",
      "w=\n",
      "[[ -2.931125  ]\n",
      " [  4.233014  ]\n",
      " [ -1.7471049 ]\n",
      " [  3.9639363 ]\n",
      " [ -0.6188207 ]\n",
      " [ 20.903952  ]\n",
      " [  2.2066133 ]\n",
      " [  0.527956  ]\n",
      " [  0.11417937]\n",
      " [ -3.3024101 ]\n",
      " [ -4.8289876 ]\n",
      " [-14.086001  ]]\n",
      "epoch=5    loss=28.7320737     b=18.8670120     \n",
      "w=\n",
      "[[ -3.144742 ]\n",
      " [  3.5907242]\n",
      " [ -0.9717251]\n",
      " [  4.2427073]\n",
      " [ -0.5914898]\n",
      " [ 22.222713 ]\n",
      " [  2.540238 ]\n",
      " [ -1.0786716]\n",
      " [  1.6560616]\n",
      " [ -2.6790192]\n",
      " [ -5.076965 ]\n",
      " [-15.257767 ]]\n",
      "\n",
      "\n",
      "每次训练的平均损失值为：\n",
      "[60.670066732870524, 47.35677556686295, 34.76074980452733, 31.188207062218684, 28.732073694279297]\n",
      "\n",
      "\n",
      "您当前随机抽取的是第307条数据\n",
      "预测值：34.133469\n",
      "标签值：50.000000\n",
      "\n",
      "\n",
      "您当前随机抽取的是第105条数据\n",
      "预测值：33.121529\n",
      "标签值：31.000000\n",
      "\n",
      "\n",
      "您当前随机抽取的是第370条数据\n",
      "预测值：15.107681\n",
      "标签值：8.800000\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "tf.disable_eager_execution()    #防止抛出异常RuntimeError: tf.placeholder() is not compatible with eager execution.\n",
    "\n",
    "class Train:\n",
    "    def __init__(self,route):\n",
    "        self.df = pd.read_csv(route,header = 0)  #读取csv文件\n",
    "        print(self.df.describe())        #显示数据摘要信息\n",
    "        self.df = self.df.values        #获取df的值\n",
    "        self.df = np.array(self.df)           #把self.df转换为np数组的形式\n",
    "        \n",
    "    def Standard(self):\n",
    "        for i in range(12):\n",
    "            self.df[:,i] = (self.df[:,i] - self.df[:,i].min())/(self.df[:,i].max() - self.df[:,i].min())\n",
    "        self.x_data = self.df[:,:12]     #self.x_data为前12列的特征数据\n",
    "        self.y_data = self.df[:,12]     #self.y_data为最后一列的标签数据\n",
    "       \n",
    "    def model(x,w,b):      #矩阵相乘,w和x\n",
    "        return tf.matmul(x,w) + b\n",
    "    \n",
    "    def Matrix(self):\n",
    "        #定义特征数据和标签数据的占位符\n",
    "        self.x = tf.placeholder(tf.float32,[None,12],name=\"X\")  #12个特征数据，12列，None表示行数未知\n",
    "        self.y = tf.placeholder(tf.float32,[None,1],name=\"Y\") #1个标签数据，1列\n",
    "        #定义一个命名空间\n",
    "        with tf.name_scope(\"Model\"):\n",
    "            #初始化值为shape=(12,1)的随机数，标准差为0.01     \n",
    "            self.w = tf.Variable(tf.random_normal([12,1],stddev = 0.01),name = \"W\")\n",
    "            self.b = tf.Variable(1.0,name = \"b\")      #b的初始值为1.0\n",
    "            self.pred = Train.model(self.x,self.w,self.b)  #预测计算操作，前向计算节点\n",
    "            \n",
    "    def LossFunction(self,train_epochs,learning_rate):\n",
    "        self.train_epochs,self.learning_rate = train_epochs,learning_rate\n",
    "        \n",
    "        with tf.name_scope(\"LossFunction\"):     #定义均方差损失函数\n",
    "            self.loss_function = tf.reduce_mean(tf.pow(self.y - self.pred,2))     #均方误差\n",
    "        #创建梯度下降优化器\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(self.loss_function)\n",
    "        self.sess =tf.Session()   #声明会话\n",
    "        self.init = tf.global_variables_initializer()    #定义初始化变量的操作\n",
    "        self.sess.run(self.init)       #启动会话\n",
    "\n",
    "\n",
    "            \n",
    "    def iteration(self):\n",
    "        \n",
    "        self.loss_list = []   #初始化空列表，用于记录每轮训练后的损失值\n",
    "        #进行迭代训练\n",
    "        for epoch in range(self.train_epochs):\n",
    "            self.loss_sum = 0.0  #每轮损失函数的总和\n",
    "            for xs,ys in zip(self.x_data,self.y_data):\n",
    "                xs = xs.reshape(1,12)    #重塑维度\n",
    "                ys = ys.reshape(1,1)\n",
    "                \n",
    "                _,self.loss = self.sess.run([self.optimizer,self.loss_function],feed_dict={self.x:xs,self.y:ys})\n",
    "                self.loss_sum = self.loss_sum + self.loss\n",
    "                \n",
    "            #打乱数据顺序\n",
    "            self.x_data,self.y_data = shuffle(self.x_data,self.y_data)\n",
    "\n",
    "            self.b0temp = self.b.eval(session = self.sess)\n",
    "            self.w0temp = self.w.eval(session = self.sess)\n",
    "\n",
    "            self.loss_average = self.loss_sum/len(self.y_data)    #平均损失率\n",
    "            self.loss_list.append(self.loss_average)     #每轮添加一次\n",
    "\n",
    "            #打印每轮训练的信息\n",
    "            print(\"epoch={0:<5}loss={1:<15.7f}b={2:<15.7f}\".format(epoch+1,self.loss_average,self.b0temp))\n",
    "            print(\"w=\")\n",
    "            print(self.w0temp)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        print(\"每次训练的平均损失值为：\")   \n",
    "        print(self.loss_list)\n",
    "        \n",
    "        \n",
    "    def test(self):\n",
    "        for i in range(3):\n",
    "            self.n = np.random.randint(506)\n",
    "            print(\"\\n\")\n",
    "            print(\"您当前随机抽取的是第{}条数据\".format(self.n))\n",
    "            self.x_test = self.x_data[self.n]\n",
    "\n",
    "            self.x_test = self.x_test.reshape(1,12)\n",
    "            self.predict = self.sess.run(self.pred,feed_dict={self.x:self.x_test})\n",
    "            print(\"预测值：%f\"% self.predict)\n",
    "            self.target = self.y_data[self.n]\n",
    "            print(\"标签值：%f\"% self.target)\n",
    "\n",
    "    \n",
    "route = r\"D:\\Code-class\\data\\boston.csv\"  \n",
    "train_epochs = eval(input(\"请输入您要进行迭代的次数：\"))        #迭代次数\n",
    "learning_rate = float(input(\"请输入你要调整的学习率：\"))    #学习率\n",
    "T = Train(route)        #创建类Train对象T\n",
    "T.Standard()           #对特征数据进行归一化\n",
    "T.Matrix()            #模型定义与定义模型函数\n",
    "T.LossFunction(train_epochs,learning_rate)     #定义损失函数\n",
    "T.iteration()       #进行迭代训练\n",
    "T.test()           #随机确定三条数据测试效果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
